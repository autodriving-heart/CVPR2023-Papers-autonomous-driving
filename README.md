# CVPR2023-Papers-autonomous-driving





CVPR2023中稿paper已经陆续放出来了，自动驾驶之心团队为大家整理了计算机视觉、BEV、分割、Occpuancy、vit、SLAM、Few-Shot/Zero-Shot、点云处理、自动驾驶等多个方向的内容，后面将会持续更新....

> **作者：汽车人 | 自动驾驶之心->：**【技术交流群】[微信公众平台 (qq.com)](https://mp.weixin.qq.com/s/bE3RXGx2X5tVpNLZGxg6VQ)

**点击关注** [@自动驾驶之心](https://www.zhihu.com/people/7-1-78-3)
第一时间看到最前沿与价值的CV/自动驾驶/AI类工作!

**强烈推荐！自动驾驶与AI学习社区：**[欢迎加入国内首个自动驾驶开发者社区！这里有最全面有效的自动驾驶与AI学习路线（感知/定位/融合）和自动驾驶与AI公司内推机会！](https://mp.weixin.qq.com/s?biz=Mzg2NzUxNTU1OA==&mid=2247522963&idx=5&sn=99ff28eb00ad73abeaf2760dc089b2bc&chksm=ceb8b75af9cf3e4cac1bfd0cddd48e1f79720bcc8c1b408ce989aca9f92a78c2af575b5b62df&token=260416221&lang=zh_CN#rd)

## **3D目标检测**

1.[Towards Domain Generalization for Multi-view 3D Object Detection in Bird-Eye-View](https://arxiv.org/abs/2303.01686)

2.[MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth Seeds for 3D Object Detection](https://arxiv.org/abs/2209.03102)

3.[Weakly Supervised Monocular 3D Object Detection using Multi-View Projection and Direction Consistency](https://arxiv.org/abs/2303.08686)

4.[Uni3D: A Unified Baseline for Multi-dataset 3D Object Detection](https://arxiv.org/abs/2303.06880)

5.[Virtual Sparse Convolution for Multimodal 3D Object Detection](https://arxiv.org/abs/2303.02314)

6.[X3KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection](https://arxiv.org/abs/2303.02203)

7.[3D Video Object Detection with Learnable Object-Centric Global Optimization](https://arxiv.org/abs/2303.15416)

8.[CAPE: Camera View Position Embedding for Multi-View 3D Object Detection](https://arxiv.org/abs/2303.10209)

9.[Bi3D: Bi-domain Active Learning for Cross-domain 3D Object Detection](https://arxiv.org/abs/2303.05886)

10.[AeDet: Azimuth-invariant Multi-view 3D Object Detection](https://arxiv.org/abs/2211.12501)

## **BEV感知**

1.[Towards Domain Generalization for Multi-view 3D Object Detection in Bird-Eye-View](https://arxiv.org/abs/2303.01686)

2.[Understanding the Robustness of 3D Object Detection with Bird's-Eye-View Representations in Autonomous Driving](https://arxiv.org/pdf/2303.17297.pdf)

3.[TBP-Former: Learning Temporal Bird's-Eye-View Pyramid for Joint Perception and Prediction in Vision-Centric Autonomous Driving](https://arxiv.org/abs/2303.09998)

## **Occpuancy**

1.[Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2302.07817)

## **分割相关**

1.[Delivering Arbitrary-Modal Semantic Segmentation](https://arxiv.org/abs/2303.01480)

2.[Token Contrast for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2303.01267)

3.[ISBNet: a 3D Point Cloud Instance Segmentation Network with Instance-aware Sampling and Box-aware Dynamic Convolution](https://arxiv.org/abs/2303.00246)

4.[Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation](https://arxiv.org/abs/2302.14250)

5.[MSeg3D: Multi-modal 3D Semantic Segmentation for Autonomous Driving](https://arxiv.org/abs/2303.08600)

6.[FastInst: A Simple Query-Based Model for Real-Time Instance Segmentation](https://arxiv.org/abs/2303.08594)

7.[InstMove: Instance Motion for Object-centric Video Segmentation](https://arxiv.org/abs/2303.08132)

8.[MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation](https://arxiv.org/abs/2303.07815)

9.[MP-Former: Mask-Piloted Transformer for Image Segmentation](https://arxiv.org/abs/2303.07336)

10.[Efficient Semantic Segmentation by Altering Resolutions for Compressed Videos](https://arxiv.org/abs/2303.07224)

11.[LaserMix for Semi-Supervised LiDAR Semantic Segmentation](https://arxiv.org/abs/2207.00026)

12.[Beyond Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks](https://arxiv.org/abs/2303.17602)

13.[EFEM: Equivariant Neural Field Expectation Maximization for 3D Object Segmentation Without Scene Supervision](https://arxiv.org/abs/2303.15440)

14.[Generative Semantic Segmentation](https://arxiv.org/abs/2303.11316)

15.[DynaMask: Dynamic Mask Selection for Instance Segmentation](https://arxiv.org/abs/2303.07868)

16. [Conflict-Based Cross-View Consistency for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2303.01276)

## **SLAM**

1.[Renderable Neural Radiance Map for Visual Navigation](https://arxiv.org/abs/2303.00304)

## **Transformer**

1.[Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves](https://arxiv.org/abs/2303.01112)

2.[Reversible Vision Transformers](https://arxiv.org/abs/2302.04869)

3.[BiFormer: Vision Transformer with Bi-Level Routing Attention](https://arxiv.org/abs/2303.08810)

4.[PVO: Panoptic Visual Odometry](https://arxiv.org/abs/2207.01610)

## **Few-Shot/Zero-Shot**

1.[Zero-shot Object Counting](https://arxiv.org/abs/2303.02001)

## **Diffusion Model**

1.[Person Image Synthesis via Denoising Diffusion Model](https://arxiv.org/abs/2211.12500)

2.[Controllable Mesh Generation Through Sparse Latent Point Diffusion Models](https://arxiv.org/abs/2303.07938)

3.[Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models](https://arxiv.org/abs/2303.04803)

## **知识蒸馏**

1.[Learning to Retain while Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation](https://arxiv.org/abs/2302.14290)

## **点云相关**

1.[ACL-SPC: Adaptive Closed-Loop system for Self-Supervised Point Cloud Completion](https://arxiv.org/abs/2303.01979)

2.[PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees](https://arxiv.org/abs/2303.01959)

3.[Neural Intrinsic Embedding for Non-rigid Point Cloud Matching](https://arxiv.org/abs/2303.01038)

4.[Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting](https://arxiv.org/abs/2302.13130)

5.[Rotation-Invariant Transformer for Point Cloud Matching](https://arxiv.org/abs/2303.08231)

6.[Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis](https://arxiv.org/abs/2303.08134)

7.[SCPNet: Semantic Scene Completion on Point Cloud](https://arxiv.org/abs/2303.06884)

8.[CLIP2Scene: Towards Label-Efficient 3D Scene Understanding by CLIP](https://arxiv.org/abs/2301.04926)

9.[PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations](https://arxiv.org/abs/2303.16958)

10.[Binarizing Sparse Convolutional Networks for Efficient Point Cloud Analysis](https://arxiv.org/abs/2303.15493)

## **轨迹预测**

1.[IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint Multi-Agent Trajectory Prediction](https://arxiv.org/abs/2303.00575)

## **异常检测**

1.[Multimodal Industrial Anomaly Detection via Hybrid Fusion](https://arxiv.org/abs/2303.00601)

## **4D Radar**

1.[Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision](https://arxiv.org/abs/2303.00462)

## 目标检测

1.[MixTeacher: Mining Promising Labels with Mixed Scale Teacher for Semi-Supervised Object Detection](https://arxiv.org/abs/2303.09061)

2.[Lite DETR : An Interleaved Multi-Scale Encoder for Efficient DETR](https://arxiv.org/abs/2303.07335)

3.[Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection](https://arxiv.org/abs/2303.05892)

## 目标跟踪

1.[Referring Multi-Object Tracking](https://arxiv.org/abs/2303.03366)

2.[Visual Prompt Multi-Modal Tracking](https://arxiv.org/abs/2303.10826)

3.[MotionTrack: Learning Robust Short-term and Long-term Motions for Multi-Object Tracking](https://arxiv.org/abs/2303.10404)

## 深度估计

1.[Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2211.13202)

## 车道线检测

1.[BEV-LaneDet: a Simple and Effective 3D Lane Detection Baseline](https://arxiv.org/abs/2210.06006)

## 其它

1.[PMatch: Paired Masked Image Modeling for Dense Geometric Matching](https://arxiv.org/abs/2303.17342)

2.[Detecting Everything in the Open World: Towards Universal Object Detection](https://arxiv.org/abs/2303.11749)

3.[One-to-Few Label Assignment for End-to-End Dense Detection](https://arxiv.org/abs/2303.11567)

4.[V2V4Real: A Real-world Large-scale Dataset for Vehicle-to-Vehicle Cooperative Perception](https://arxiv.org/abs/2303.07601)